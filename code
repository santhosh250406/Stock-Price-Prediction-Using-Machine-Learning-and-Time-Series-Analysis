import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import LabelEncoder  # For encoding categorical strings

# Load the dataset
data = pd.read_csv('/content/drive/MyDrive/Hist_BS_Fin_Stmt.csv')

# Identify the column containing dates/strings (replace 'Date' if necessary)
date_col = 'quarter(10yrs)' 

# Preprocess the date/string column
if pd.api.types.is_string_dtype(data[date_col]):
  try:
    # Attempt to convert to datetime format (if dates)
    data[date_col] = pd.to_datetime(data[date_col])
  except ValueError:
    # Handle non-convertible strings (e.g., label encoding)
    le = LabelEncoder()
    data[date_col] = le.fit_transform(data[date_col])

# Select numerical columns for normalization (excluding the date/string column)
numerical_cols = [col for col in data.columns if col != date_col and pd.api.types.is_numeric_dtype(data[col])]
data_to_scale = data[numerical_cols]

# Normalize the numerical data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data_to_scale)

# Create sequences for LSTM
def create_dataset(dataset, look_back=60):
    X, Y = [], []
    for i in range(len(dataset) - look_back - 1):
        a = dataset[i:(i + look_back), :]  # Use all features
        X.append(a)
        Y.append(dataset[i + look_back, :])  # Use all features for prediction
    return np.array(X), np.array(Y)

# Split data into training and testing sets
train_size = int(len(scaled_data) * 0.8)
test_size = len(scaled_data) - train_size
train_data, test_data = scaled_data[0:train_size, :], scaled_data[train_size:len(scaled_data), :]

# Create sequences for training and testing data
look_back = 60  # Adjust look_back window as needed
X_train, y_train = create_dataset(train_data, look_back)
X_test, y_test = create_dataset(test_data, look_back)

# Reshape input to be [samples, time steps, features] which is required for LSTM
# Assuming you want to predict the first column (replace with the actual target column index)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))

# Create the LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(X_train.shape[2]))  # Output layer with the same number of features

# Compile the model
model.compile(loss='mean_squared_error', optimizer='adam')

# Train the model
model.fit(X_train, y_train, epochs=100, batch_size=32)

# Make predictions
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

# Invert predictions back to original scale
train_predict = scaler.inverse_transform(train_predict)
y_train = scaler.inverse_transform(y_train)
test_predict = scaler.inverse_transform(test_predict)
y_test = scaler.inverse_transform(y_test)

# Handle potential NaN values before calculating RMSE
y_train = np.nan_to_num(y_train)  # Replace NaN with 0 (adjust as needed)
train_predict = np.nan_to_num(train_predict)
y_test = np.nan_to_num(y_test)
test_predict = np.nan_to_num(test_predict)

# Evaluate model performance (calculate root mean squared error)
from sklearn.metrics import mean_squared_error
train_rmse = np.sqrt(mean_squared_error(y_train[:, 0], train_predict[:, 0]))  # Assuming you're predicting the first column
test_rmse = np.sqrt(mean_squared_error(y_test[:, 0], test_predict[:, 0]))
print('Train RMSE:', train_rmse)
print('Test RMSE:', test_rmse)

# Plot the results (for the first predicted column)
import matplotlib.pyplot as plt

plt.figure(figsize=(16, 6))
plt.plot(y_test[:, 0])
plt.plot(test_predict[:, 0])
plt.title('Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend(['Actual', 'Predicted'])
plt.show()
